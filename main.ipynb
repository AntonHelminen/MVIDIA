{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14222c08-76d7-47e1-8e3c-545962390bc9",
   "metadata": {},
   "source": [
    "# MVDIA - Practical Assignment\n",
    "\n",
    "**Authors**: Anton Helminen & Veikka Immonen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c4a9e4-d21a-408b-97f2-85d1e0052002",
   "metadata": {},
   "source": [
    "## Load modules\n",
    "\n",
    "Modules used for the system. To install: `pip install [module]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99c413f-c17a-4373-803e-43444ecdaeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.transforms import v2\n",
    "from rtmlib import Wholebody, draw_skeleton\n",
    "\n",
    "# Custom libraries\n",
    "from Feature_extraction import opt_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a08dec7-66c0-4834-8a59-2fef0ab2b973",
   "metadata": {},
   "source": [
    "## Device\n",
    "\n",
    "Define preferred device for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1705fe2b-a9cf-40d8-a9c0-d7234f402515",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' # or 'cpu'\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f59855-8eac-4398-9081-f8f2af39f38e",
   "metadata": {},
   "source": [
    "## Load models and processing functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41ad5e86-ecd8-428e-a5d7-ec38d40c524b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 16:20:58.231814983 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n",
      "2024-03-29 16:20:58.231830243 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n",
      "2024-03-29 16:20:58.505237524 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n",
      "2024-03-29 16:20:58.505254514 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load /home/veikka/.cache/rtmlib/hub/checkpoints/yolox_m_8xb8-300e_humanart-c2c7a14a.onnx with onnxruntime backend\n",
      "load /home/veikka/.cache/rtmlib/hub/checkpoints/rtmw-x_simcc-cocktail13_pt-ucoco_270e-256x192-fbef0d61_20230925.onnx with onnxruntime backend\n"
     ]
    }
   ],
   "source": [
    "wholebody = Wholebody(\n",
    "    to_openpose=False,\n",
    "    mode='balanced',\n",
    "    backend='onnxruntime', device=device\n",
    ")\n",
    "\n",
    "model = torch.load('model.pt').to(device)\n",
    "model.eval()\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize((128, 128)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b10d966-eba8-4f12-88b4-f0553a966e4c",
   "metadata": {},
   "source": [
    "## Classification function\n",
    "\n",
    "```def classify(image_stream: list[ndarray]) -> int```\n",
    "\n",
    "- `image_stream`: video sample as a list of images (`ndarray`, `dtype=uint8`)\n",
    "- Returns: class from 1 to 32 as integer, -1 if fails.\n",
    "\n",
    "Recommended: images are opened using `cv2.imread` without any color channel manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a78fb34-d058-454d-b75b-a113328cb13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(image_stream):\n",
    "\n",
    "    try:\n",
    "        pre_processed_images = []\n",
    "        for image in image_stream:\n",
    "            keypoints, scores = wholebody(image)\n",
    "            # Skeleton image\n",
    "            img_spooky = np.zeros(image.shape, dtype=np.uint8)\n",
    "            img_spooky = draw_skeleton(img_spooky, keypoints, scores, kpt_thr=0.5)\n",
    "            pre_processed_images.append(img_spooky)\n",
    "        # Added optical flow\n",
    "        if (len(pre_processed_images) > 1):\n",
    "            image_final = opt_flow(pre_processed_images)\n",
    "        else:\n",
    "            image_final = pre_processed_images[0]\n",
    "    except:\n",
    "        print(\"Sample preprocessing failed, halt...\")\n",
    "        return -1\n",
    "\n",
    "    image_final = cv2.cvtColor(image_final, cv2.COLOR_BGR2RGB)\n",
    "    reshaped = transform(image_final).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model(reshaped).squeeze()\n",
    "\n",
    "    return output.argmax().cpu().item() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31260e7-04c5-4b93-ba46-de0688ebb0f6",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Sample is from training set, class 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5387fd0a-da4b-41b7-beb5-af227db009ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_path = './test_sample/557'\n",
    "sample = [cv2.imread(f'{sample_path}.{i}.jpg') for i in range(7)]\n",
    "classify(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
